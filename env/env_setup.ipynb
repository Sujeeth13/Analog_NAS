{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import os\n",
    "from VQVAE_environment import VQVAE_Env\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy surrogate model, decoder, and codebook to test the environment\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class MockSurrogateModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def evaluate(self, decoded_state):\n",
    "        # Return a dummy accuracy value\n",
    "        return np.random.random()\n",
    "\n",
    "class MockDecoder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def decode(self, state):\n",
    "        # Return a dummy decoded state\n",
    "        return state\n",
    "\n",
    "# Create a dummy codebook as a numpy array\n",
    "# Assuming the embed_dim is 10 and you have 100 embeddings plus 1 for the stop action\n",
    "mock_codebook = np.random.rand(100, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your environment with the mock components\n",
    "env = VQVAE_Env(embed_dim=10, num_embeddings=100, max_allowed_actions=200,\n",
    "                surrogate_model=MockSurrogateModel(), decoder=MockDecoder(), codebook=mock_codebook,\n",
    "                num_previous_actions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using check_env from stable baselines 3 to check if the environment is compatible with stable baselines\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Observation: ({'latent_vector': array([ 0.9183627 , -0.4344771 ,  1.2901202 ,  0.08363848, -0.44587874,\n",
      "        2.771025  , -1.1156787 ,  1.4472796 , -0.6398812 , -0.24225442],\n",
      "      dtype=float32), 'action_history': array([-1, -1, -1, -1], dtype=int32)}, {})\n",
      "Taking action: 153\n",
      "New Observation: {'latent_vector': array([ 0.9183627 , -0.4344771 ,  1.2901202 ,  0.8510552 , -0.44587874,\n",
      "        2.771025  , -1.1156787 ,  1.4472796 , -0.6398812 , -0.24225442],\n",
      "      dtype=float32), 'action_history': array([ -1,  -1,  -1, 153], dtype=int32)}\n",
      "Reward: 0.07863918608774867\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 48\n",
      "New Observation: {'latent_vector': array([ 0.9183627 , -0.4344771 ,  1.2901202 ,  0.8510552 , -0.44587874,\n",
      "        2.771025  , -1.1156787 ,  1.4472796 ,  0.8455125 , -0.24225442],\n",
      "      dtype=float32), 'action_history': array([ -1,  -1, 153,  48], dtype=int32)}\n",
      "Reward: 0.24013735096384758\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 901\n",
      "New Observation: {'latent_vector': array([ 0.9183627 ,  0.9318859 ,  1.2901202 ,  0.8510552 , -0.44587874,\n",
      "        2.771025  , -1.1156787 ,  1.4472796 ,  0.8455125 , -0.24225442],\n",
      "      dtype=float32), 'action_history': array([ -1, 153,  48, 901], dtype=int32)}\n",
      "Reward: 0.652623354945416\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 829\n",
      "New Observation: {'latent_vector': array([ 0.9183627 ,  0.9318859 ,  1.2901202 ,  0.8510552 , -0.44587874,\n",
      "        2.771025  , -1.1156787 ,  1.4472796 ,  0.8455125 ,  0.38783485],\n",
      "      dtype=float32), 'action_history': array([153,  48, 901, 829], dtype=int32)}\n",
      "Reward: -0.48055166830724494\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 481\n",
      "New Observation: {'latent_vector': array([ 0.9183627 ,  0.41396183,  1.2901202 ,  0.8510552 , -0.44587874,\n",
      "        2.771025  , -1.1156787 ,  1.4472796 ,  0.8455125 ,  0.38783485],\n",
      "      dtype=float32), 'action_history': array([ 48, 901, 829, 481], dtype=int32)}\n",
      "Reward: -0.20804687620383955\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 474\n",
      "New Observation: {'latent_vector': array([ 0.9183627 ,  0.41396183,  1.2901202 ,  0.8510552 ,  0.15709157,\n",
      "        2.771025  , -1.1156787 ,  1.4472796 ,  0.8455125 ,  0.38783485],\n",
      "      dtype=float32), 'action_history': array([901, 829, 481, 474], dtype=int32)}\n",
      "Reward: -0.25049737343487843\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 886\n",
      "New Observation: {'latent_vector': array([0.9183627 , 0.41396183, 1.2901202 , 0.8510552 , 0.15709157,\n",
      "       2.771025  , 0.68341744, 1.4472796 , 0.8455125 , 0.38783485],\n",
      "      dtype=float32), 'action_history': array([829, 481, 474, 886], dtype=int32)}\n",
      "Reward: 0.09312799360173585\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 948\n",
      "New Observation: {'latent_vector': array([0.9183627 , 0.41396183, 1.2901202 , 0.8510552 , 0.15709157,\n",
      "       2.771025  , 0.68341744, 1.4472796 , 0.10974561, 0.38783485],\n",
      "      dtype=float32), 'action_history': array([481, 474, 886, 948], dtype=int32)}\n",
      "Reward: 0.5796814115278454\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 12\n",
      "New Observation: {'latent_vector': array([0.9183627 , 0.41396183, 0.525087  , 0.8510552 , 0.15709157,\n",
      "       2.771025  , 0.68341744, 1.4472796 , 0.10974561, 0.38783485],\n",
      "      dtype=float32), 'action_history': array([474, 886, 948,  12], dtype=int32)}\n",
      "Reward: -0.00845475623587566\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 617\n",
      "New Observation: {'latent_vector': array([0.9183627 , 0.41396183, 0.525087  , 0.8510552 , 0.15709157,\n",
      "       2.771025  , 0.68341744, 0.3457701 , 0.10974561, 0.38783485],\n",
      "      dtype=float32), 'action_history': array([886, 948,  12, 617], dtype=int32)}\n",
      "Reward: 0.23377958389852282\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 92\n",
      "New Observation: {'latent_vector': array([0.9183627 , 0.41396183, 0.25898954, 0.8510552 , 0.15709157,\n",
      "       2.771025  , 0.68341744, 0.3457701 , 0.10974561, 0.38783485],\n",
      "      dtype=float32), 'action_history': array([948,  12, 617,  92], dtype=int32)}\n",
      "Reward: -0.34500133447768644\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 560\n",
      "New Observation: {'latent_vector': array([0.19295795, 0.41396183, 0.25898954, 0.8510552 , 0.15709157,\n",
      "       2.771025  , 0.68341744, 0.3457701 , 0.10974561, 0.38783485],\n",
      "      dtype=float32), 'action_history': array([ 12, 617,  92, 560], dtype=int32)}\n",
      "Reward: 0.08819906205392503\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 177\n",
      "New Observation: {'latent_vector': array([0.19295795, 0.41396183, 0.25898954, 0.8510552 , 0.15709157,\n",
      "       2.771025  , 0.68341744, 0.9892451 , 0.10974561, 0.38783485],\n",
      "      dtype=float32), 'action_history': array([617,  92, 560, 177], dtype=int32)}\n",
      "Reward: -0.06466441598861106\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 387\n",
      "New Observation: {'latent_vector': array([0.19295795, 0.41396183, 0.25898954, 0.8510552 , 0.15709157,\n",
      "       2.771025  , 0.68341744, 0.9558507 , 0.10974561, 0.38783485],\n",
      "      dtype=float32), 'action_history': array([ 92, 560, 177, 387], dtype=int32)}\n",
      "Reward: -0.07043783841006701\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 496\n",
      "New Observation: {'latent_vector': array([0.19295795, 0.41396183, 0.25898954, 0.8510552 , 0.15709157,\n",
      "       2.771025  , 0.07608311, 0.9558507 , 0.10974561, 0.38783485],\n",
      "      dtype=float32), 'action_history': array([560, 177, 387, 496], dtype=int32)}\n",
      "Reward: -0.48213567658454615\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 843\n",
      "New Observation: {'latent_vector': array([0.19295795, 0.41396183, 0.25898954, 0.45332372, 0.15709157,\n",
      "       2.771025  , 0.07608311, 0.9558507 , 0.10974561, 0.38783485],\n",
      "      dtype=float32), 'action_history': array([177, 387, 496, 843], dtype=int32)}\n",
      "Reward: 0.8682422087561429\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 581\n",
      "New Observation: {'latent_vector': array([0.19295795, 0.54694647, 0.25898954, 0.45332372, 0.15709157,\n",
      "       2.771025  , 0.07608311, 0.9558507 , 0.10974561, 0.38783485],\n",
      "      dtype=float32), 'action_history': array([387, 496, 843, 581], dtype=int32)}\n",
      "Reward: -0.3200117959428186\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 32\n",
      "New Observation: {'latent_vector': array([0.19295795, 0.54694647, 0.7766801 , 0.45332372, 0.15709157,\n",
      "       2.771025  , 0.07608311, 0.9558507 , 0.10974561, 0.38783485],\n",
      "      dtype=float32), 'action_history': array([496, 843, 581,  32], dtype=int32)}\n",
      "Reward: -0.22168088648302875\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 871\n",
      "New Observation: {'latent_vector': array([0.19295795, 0.04501911, 0.7766801 , 0.45332372, 0.15709157,\n",
      "       2.771025  , 0.07608311, 0.9558507 , 0.10974561, 0.38783485],\n",
      "      dtype=float32), 'action_history': array([843, 581,  32, 871], dtype=int32)}\n",
      "Reward: 0.47669902779573614\n",
      "Done: False\n",
      "Truncate: False\n",
      "Info: {}\n",
      "---\n",
      "Taking action: 968\n",
      "New Observation: {'latent_vector': array([0.19295795, 0.04501911, 0.7766801 , 0.45332372, 0.15709157,\n",
      "       2.771025  , 0.07608311, 0.9558507 , 0.00803622, 0.38783485],\n",
      "      dtype=float32), 'action_history': array([581,  32, 871, 968], dtype=int32)}\n",
      "Reward: -0.7380720907945796\n",
      "Done: True\n",
      "Truncate: True\n",
      "Info: {}\n",
      "---\n",
      "Episode finished after 20 timesteps.\n"
     ]
    }
   ],
   "source": [
    "# Manual testing of the environment\n",
    "\n",
    "# Create an instance of the environment with dummy parameters\n",
    "env = VQVAE_Env(\n",
    "    embed_dim=10,\n",
    "    num_embeddings=100,\n",
    "    max_allowed_actions=20,\n",
    "    surrogate_model=MockSurrogateModel(),  # Dummy surrogate model\n",
    "    decoder=MockDecoder(),  # Dummy decoder\n",
    "    codebook=mock_codebook  \n",
    ")\n",
    "\n",
    "# Reset the environment to start a new episode\n",
    "observation = env.reset()\n",
    "print(\"Initial Observation:\", observation)\n",
    "\n",
    "# Take actions in a loop until the episode ends\n",
    "done = False\n",
    "while not done:\n",
    "    # Sample a random action\n",
    "    action = env.sample_action()\n",
    "    print(\"Taking action:\", action)\n",
    "\n",
    "    # Perform the action in the environment\n",
    "    observation, reward, done, truncate, info = env.step(action)\n",
    "    print(\"New Observation:\", observation)\n",
    "    print(\"Reward:\", reward)\n",
    "    print(\"Done:\", done)\n",
    "    print(\"Truncate:\", truncate)\n",
    "    print(\"Info:\", info)\n",
    "    print(\"---\")\n",
    "\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps.\".format(env.step_count))\n",
    "        break\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Baseline Training Script (with dummy Surrogate & Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'models'\n",
    "log_dir = 'logs'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the env\n",
    "vec_env = make_vec_env(VQVAE_Env, n_envs=1, env_kwargs=dict(embed_dim=10,\n",
    "    num_embeddings=100,\n",
    "    max_allowed_actions=20,\n",
    "    surrogate_model=MockSurrogateModel(),  # Dummy surrogate model\n",
    "    decoder=MockDecoder(),  # Dummy decoder\n",
    "    codebook=mock_codebook ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('action_history', array([[-1, -1, -1, -1]], dtype=int32)),\n",
       "             ('latent_vector',\n",
       "              array([[ 0.10479282, -1.0372716 ,  1.3703396 ,  0.408466  , -0.2843564 ,\n",
       "                      -1.0075978 ,  0.5536992 , -2.2233102 , -0.07724699, -1.0645074 ]],\n",
       "                    dtype=float32))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/wandb/run-20240416_192251-udd0b8vn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/trex-ai/Test/runs/udd0b8vn' target=\"_blank\">confused-gorge-2</a></strong> to <a href='https://wandb.ai/trex-ai/Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/trex-ai/Test' target=\"_blank\">https://wandb.ai/trex-ai/Test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/trex-ai/Test/runs/udd0b8vn' target=\"_blank\">https://wandb.ai/trex-ai/Test/runs/udd0b8vn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": 25000\n",
    "}\n",
    "\n",
    "run = wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"Test\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to logs/PPO_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.8     |\n",
      "|    ep_rew_mean     | 0.464    |\n",
      "| time/              |          |\n",
      "|    fps             | 4440     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.9        |\n",
      "|    ep_rew_mean          | 0.518       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2075        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027024012 |\n",
      "|    clip_fraction        | 0.438       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.9        |\n",
      "|    explained_variance   | -1.51       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.084      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.105      |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 20         |\n",
      "|    ep_rew_mean          | 0.517      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1791       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 3          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03122745 |\n",
      "|    clip_fraction        | 0.503      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.89      |\n",
      "|    explained_variance   | -0.0211    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.111     |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.118     |\n",
      "|    value_loss           | 0.114      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 19.6       |\n",
      "|    ep_rew_mean          | 0.506      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1665       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 4          |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03222262 |\n",
      "|    clip_fraction        | 0.507      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.88      |\n",
      "|    explained_variance   | -0.00144   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0906    |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.12      |\n",
      "|    value_loss           | 0.119      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 19.8      |\n",
      "|    ep_rew_mean          | 0.528     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1609      |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 6         |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0330295 |\n",
      "|    clip_fraction        | 0.523     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.87     |\n",
      "|    explained_variance   | 0.0256    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.101    |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.122    |\n",
      "|    value_loss           | 0.11      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 20         |\n",
      "|    ep_rew_mean          | 0.47       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1567       |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03413942 |\n",
      "|    clip_fraction        | 0.509      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.86      |\n",
      "|    explained_variance   | 0.0582     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.105     |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.121     |\n",
      "|    value_loss           | 0.113      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.8        |\n",
      "|    ep_rew_mean          | 0.501       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1543        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034111816 |\n",
      "|    clip_fraction        | 0.494       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.85       |\n",
      "|    explained_variance   | 0.0259      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.101      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.12       |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.9        |\n",
      "|    ep_rew_mean          | 0.464       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1518        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034134276 |\n",
      "|    clip_fraction        | 0.499       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.84       |\n",
      "|    explained_variance   | 0.0327      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.108      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.119      |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.5        |\n",
      "|    ep_rew_mean          | 0.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1502        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034304783 |\n",
      "|    clip_fraction        | 0.494       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.83       |\n",
      "|    explained_variance   | 0.0577      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0989     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.119      |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.9        |\n",
      "|    ep_rew_mean          | 0.487       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1486        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033356376 |\n",
      "|    clip_fraction        | 0.485       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.83       |\n",
      "|    explained_variance   | 0.0361      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.102      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.118      |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.9        |\n",
      "|    ep_rew_mean          | 0.48        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1469        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033311673 |\n",
      "|    clip_fraction        | 0.466       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.82       |\n",
      "|    explained_variance   | 0.0603      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.101      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.116      |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 19.9       |\n",
      "|    ep_rew_mean          | 0.488      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1462       |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03463162 |\n",
      "|    clip_fraction        | 0.465      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.81      |\n",
      "|    explained_variance   | 0.0471     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.121     |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.116     |\n",
      "|    value_loss           | 0.108      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 19.8       |\n",
      "|    ep_rew_mean          | 0.494      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1456       |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03399954 |\n",
      "|    clip_fraction        | 0.461      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.8       |\n",
      "|    explained_variance   | 0.0404     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0966    |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.115     |\n",
      "|    value_loss           | 0.112      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>rollout/ep_len_mean</td><td>▆▇█▃▅█▅▇▁▇▆▇▅</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▇▇▆█▂▅▁▆▄▃▄▄</td></tr><tr><td>time/fps</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/approx_kl</td><td>▁▅▆▇████▇▇█▇</td></tr><tr><td>train/clip_fraction</td><td>▁▆▇█▇▆▆▆▅▃▃▃</td></tr><tr><td>train/clip_range</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/entropy_loss</td><td>▁▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>train/explained_variance</td><td>▁███████████</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▇▅▄▅▃▅▅▅▁▆</td></tr><tr><td>train/policy_gradient_loss</td><td>█▃▂▁▂▂▂▂▃▃▄▄</td></tr><tr><td>train/value_loss</td><td>█▂▃▁▂▃▂▁▃▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>26624</td></tr><tr><td>rollout/ep_len_mean</td><td>19.83</td></tr><tr><td>rollout/ep_rew_mean</td><td>0.49422</td></tr><tr><td>time/fps</td><td>1456.0</td></tr><tr><td>train/approx_kl</td><td>0.034</td></tr><tr><td>train/clip_fraction</td><td>0.46099</td></tr><tr><td>train/clip_range</td><td>0.2</td></tr><tr><td>train/entropy_loss</td><td>-6.80211</td></tr><tr><td>train/explained_variance</td><td>0.0404</td></tr><tr><td>train/learning_rate</td><td>0.0003</td></tr><tr><td>train/loss</td><td>-0.09659</td></tr><tr><td>train/policy_gradient_loss</td><td>-0.11477</td></tr><tr><td>train/value_loss</td><td>0.11164</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-gorge-2</strong> at: <a href='https://wandb.ai/trex-ai/Test/runs/udd0b8vn' target=\"_blank\">https://wandb.ai/trex-ai/Test/runs/udd0b8vn</a><br/> View project at: <a href='https://wandb.ai/trex-ai/Test' target=\"_blank\">https://wandb.ai/trex-ai/Test</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240416_192251-udd0b8vn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the agent\n",
    "model = PPO(config['policy'], vec_env, verbose=1, tensorboard_log=log_dir)\n",
    "model.learn(\n",
    "    total_timesteps=config[\"total_timesteps\"],\n",
    "    callback=WandbCallback(\n",
    "        model_save_path=f\"models/{run.id}\",\n",
    "        verbose=2,\n",
    "    ),\n",
    ")\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Action:  [955]\n",
      "obs= OrderedDict([('action_history', array([[ -1,  -1,  -1, 955]], dtype=int32)), ('latent_vector', array([[ 0.05283138, -0.09423001,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [0.5419346] done= [False]\n",
      "Step 2\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[ -1,  -1, 955, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [0.4386297] done= [False]\n",
      "Step 3\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[ -1, 955, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [-0.22091103] done= [False]\n",
      "Step 4\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[955, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [-0.08159108] done= [False]\n",
      "Step 5\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [0.24929601] done= [False]\n",
      "Step 6\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [-0.25281563] done= [False]\n",
      "Step 7\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [0.20796894] done= [False]\n",
      "Step 8\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [-0.10844392] done= [False]\n",
      "Step 9\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [-0.6976873] done= [False]\n",
      "Step 10\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [0.08249594] done= [False]\n",
      "Step 11\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [0.51485085] done= [False]\n",
      "Step 12\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [-0.37892142] done= [False]\n",
      "Step 13\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [0.25185964] done= [False]\n",
      "Step 14\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [-0.51519626] done= [False]\n",
      "Step 15\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [0.08700968] done= [False]\n",
      "Step 16\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [0.1362022] done= [False]\n",
      "Step 17\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [0.37352192] done= [False]\n",
      "Step 18\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [-0.31032613] done= [False]\n",
      "Step 19\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[921, 921, 921, 921]], dtype=int32)), ('latent_vector', array([[ 0.05283138,  0.6752847 ,  0.31997174, -0.37998945,  0.15682319,\n",
      "         0.20595308,  0.30689126,  0.27883932, -1.5004084 ,  0.84475845]],\n",
      "      dtype=float32))]) reward= [0.1585781] done= [False]\n",
      "Step 20\n",
      "Action:  [921]\n",
      "obs= OrderedDict([('action_history', array([[-1, -1, -1, -1]], dtype=int32)), ('latent_vector', array([[-0.5116609 , -0.57361513, -0.65562785,  0.25484824, -0.07792725,\n",
      "        -1.4990935 ,  1.0203893 ,  1.5525414 , -0.8613806 , -1.427906  ]],\n",
      "      dtype=float32))]) reward= [-0.47524548] done= [ True]\n",
      "Goal reached! reward= [-0.47524548]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tawab/miniconda3/envs/DL/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:243: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
      "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
     ]
    }
   ],
   "source": [
    "# Test the trained agent\n",
    "# using the vecenv\n",
    "obs = vec_env.reset()\n",
    "n_steps = 20\n",
    "for step in range(n_steps):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    print(f\"Step {step + 1}\")\n",
    "    print(\"Action: \", action)\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    print(\"obs=\", obs, \"reward=\", reward, \"done=\", done)\n",
    "    vec_env.render()\n",
    "    if done:\n",
    "        # Note that the VecEnv resets automatically\n",
    "        # when a done signal is encountered\n",
    "        print(\"Goal reached!\", \"reward=\", reward)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masaficontact\u001b[0m (\u001b[33mtrex-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/wandb/run-20240416_183840-vgt8hlk5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/trex-ai/my-awesome-project/runs/vgt8hlk5' target=\"_blank\">ruby-tree-1</a></strong> to <a href='https://wandb.ai/trex-ai/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/trex-ai/my-awesome-project' target=\"_blank\">https://wandb.ai/trex-ai/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/trex-ai/my-awesome-project/runs/vgt8hlk5' target=\"_blank\">https://wandb.ai/trex-ai/my-awesome-project/runs/vgt8hlk5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▄▇▇█▇██</td></tr><tr><td>loss</td><td>█▅▃▃▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.7922</td></tr><tr><td>loss</td><td>0.20247</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ruby-tree-1</strong> at: <a href='https://wandb.ai/trex-ai/my-awesome-project/runs/vgt8hlk5' target=\"_blank\">https://wandb.ai/trex-ai/my-awesome-project/runs/vgt8hlk5</a><br/> View project at: <a href='https://wandb.ai/trex-ai/my-awesome-project' target=\"_blank\">https://wandb.ai/trex-ai/my-awesome-project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240416_183840-vgt8hlk5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reference code for later!!\n",
    "\n",
    "\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "\n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Surrogate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from SurrogateModel import SurrogateModel\n",
    "df = pd.read_csv('/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/data/dataset_cifar10_v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with Examples from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k0/y02lb3y56ys_56xwpxd8xg2r0000gn/T/ipykernel_14934/560626424.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"convblock1\"] = df[\"convblock1\"].replace(value_mapping).astype('float32')\n"
     ]
    }
   ],
   "source": [
    "# Use orginal data from the training set to test the Surrogate model evaluate function\n",
    "value_mapping = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4}\n",
    "df[\"convblock1\"] = df[\"convblock1\"].replace(value_mapping).astype('float32')\n",
    "df[\"convblock2\"] = df[\"convblock2\"].replace(value_mapping).astype('float32')\n",
    "df[\"convblock3\"] = df[\"convblock3\"].replace(value_mapping).astype('float32')\n",
    "df[\"convblock4\"] = df[\"convblock4\"].replace(value_mapping).astype('float32')\n",
    "df[\"convblock5\"] = df[\"convblock5\"].replace(value_mapping).astype('float32')\n",
    "data = df.iloc[:,:22]\n",
    "x = data.head()\n",
    "normal_input_value = x.values\n",
    "normal_input_value = torch.tensor(normal_input_value, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_model = SurrogateModel('/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/surrogate_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted accuracy: [0.92884475 0.9123806  0.7297597  0.77937865 0.79452664]\n",
      "Actual accuracy: 0    0.923597\n",
      "1    0.922466\n",
      "2    0.876552\n",
      "3    0.658484\n",
      "4    0.874308\n",
      "Name: 1_day_accuracy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pred = S_model.evaluate(normal_input_value)\n",
    "print('Predicted accuracy:', pred)\n",
    "print('Actual accuracy:', df['1_day_accuracy'].iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with Predictions from Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_data = torch.tensor([[64.6800,  3.0988,  8.2265,  6.8180,  4.8326,  3.3803,  2.1295,  2.5059,\n",
    "          2.5093,  6.3183,  1.9964,  1.8305,  4.9266,  1.5593,  1.7053,  3.8663,\n",
    "          1.2503,  1.2723,  2.7812,  0.6364,  0.0000,  1.6426],\n",
    "        [64.4652,  3.0861,  8.2008,  6.7940,  4.8138,  3.3655,  2.1192,  2.4984,\n",
    "          2.5002,  6.3002,  1.9876,  1.8226,  4.9095,  1.5518,  1.6977,  3.8513,\n",
    "          1.2425,  1.2670,  2.7679,  0.6332,  0.0000,  1.6346],\n",
    "        [64.2907,  3.0758,  8.1799,  6.7745,  4.7985,  3.3535,  2.1109,  2.4924,\n",
    "          2.4928,  6.2855,  1.9804,  1.8161,  4.8957,  1.5458,  1.6916,  3.8392,\n",
    "          1.2363,  1.2627,  2.7571,  0.6306,  0.0000,  1.6282],\n",
    "        [64.6227,  3.0954,  8.2196,  6.8116,  4.8276,  3.3763,  2.1267,  2.5039,\n",
    "          2.5069,  6.3135,  1.9941,  1.8284,  4.9220,  1.5573,  1.7033,  3.8623,\n",
    "          1.2482,  1.2709,  2.7776,  0.6355,  0.0000,  1.6405],\n",
    "        [64.2712,  3.0746,  8.1775,  6.7723,  4.7968,  3.3522,  2.1100,  2.4917,\n",
    "          2.4920,  6.2839,  1.9796,  1.8154,  4.8941,  1.5451,  1.6909,  3.8378,\n",
    "          1.2356,  1.2623,  2.7559,  0.6303,  0.0000,  1.6274],\n",
    "        [64.8440,  3.1085,  8.2461,  6.8364,  4.8470,  3.3916,  2.1373,  2.5116,\n",
    "          2.5163,  6.3321,  2.0032,  1.8366,  4.9396,  1.5649,  1.7112,  3.8777,\n",
    "          1.2562,  1.2763,  2.7913,  0.6388,  0.0000,  1.6487],\n",
    "        [65.2637,  3.1333,  8.2964,  6.8833,  4.8837,  3.4204,  2.1572,  2.5261,\n",
    "          2.5341,  6.3674,  2.0204,  1.8522,  4.9729,  1.5795,  1.7260,  3.9070,\n",
    "          1.2713,  1.2867,  2.8173,  0.6451,  0.0000,  1.6642],\n",
    "        [64.2908,  3.0758,  8.1799,  6.7745,  4.7985,  3.3535,  2.1109,  2.4924,\n",
    "          2.4928,  6.2855,  1.9804,  1.8161,  4.8957,  1.5458,  1.6916,  3.8392,\n",
    "          1.2363,  1.2627,  2.7571,  0.6306,  0.0000,  1.6282],\n",
    "        [64.6034,  3.0943,  8.2173,  6.8095,  4.8259,  3.3750,  2.1258,  2.5032,\n",
    "          2.5061,  6.3118,  1.9933,  1.8277,  4.9205,  1.5566,  1.7027,  3.8610,\n",
    "          1.2475,  1.2704,  2.7764,  0.6352,  0.0000,  1.6397],\n",
    "        [64.4813,  3.0870,  8.2027,  6.7958,  4.8152,  3.3666,  2.1200,  2.4990,\n",
    "          2.5009,  6.3016,  1.9882,  1.8232,  4.9108,  1.5524,  1.6983,  3.8525,\n",
    "          1.2431,  1.2674,  2.7689,  0.6334,  0.0000,  1.6352],\n",
    "        [65.2572,  3.1329,  8.2956,  6.8826,  4.8831,  3.4200,  2.1569,  2.5258,\n",
    "          2.5338,  6.3669,  2.0201,  1.8519,  4.9724,  1.5793,  1.7258,  3.9066,\n",
    "          1.2710,  1.2865,  2.8169,  0.6450,  0.0000,  1.6640],\n",
    "        [64.2538,  3.0736,  8.1754,  6.7704,  4.7953,  3.3510,  2.1092,  2.4911,\n",
    "          2.4913,  6.2824,  1.9789,  1.8148,  4.8927,  1.5445,  1.6903,  3.8366,\n",
    "          1.2349,  1.2618,  2.7548,  0.6300,  0.0000,  1.6268],\n",
    "        [64.9387,  3.1141,  8.2575,  6.8470,  4.8552,  3.3981,  2.1418,  2.5148,\n",
    "          2.5203,  6.3400,  2.0070,  1.8401,  4.9471,  1.5682,  1.7145,  3.8843,\n",
    "          1.2596,  1.2787,  2.7972,  0.6402,  0.0000,  1.6522],\n",
    "        [63.6988,  3.0408,  8.1090,  6.7083,  4.7467,  3.3128,  2.0828,  2.4719,\n",
    "          2.4677,  6.2357,  1.9561,  1.7942,  4.8487,  1.5252,  1.6706,  3.7979,\n",
    "          1.2150,  1.2482,  2.7204,  0.6218,  0.0000,  1.6062],\n",
    "        [63.9417,  3.0552,  8.1381,  6.7355,  4.7679,  3.3295,  2.0943,  2.4803,\n",
    "          2.4780,  6.2561,  1.9661,  1.8032,  4.8680,  1.5337,  1.6792,  3.8148,\n",
    "          1.2237,  1.2542,  2.7354,  0.6254,  0.0000,  1.6152],\n",
    "        [65.2935,  3.1350,  8.3000,  6.8867,  4.8863,  3.4225,  2.1587,  2.5271,\n",
    "          2.5354,  6.3699,  2.0216,  1.8533,  4.9753,  1.5805,  1.7271,  3.9091,\n",
    "          1.2723,  1.2874,  2.8192,  0.6455,  0.0000,  1.6653],\n",
    "        [65.2400,  3.1319,  8.2936,  6.8807,  4.8816,  3.4188,  2.1561,  2.5252,\n",
    "          2.5331,  6.3654,  2.0194,  1.8513,  4.9710,  1.5787,  1.7252,  3.9053,\n",
    "          1.2704,  1.2861,  2.8159,  0.6447,  0.0000,  1.6633],\n",
    "        [64.9390,  3.1141,  8.2575,  6.8470,  4.8553,  3.3981,  2.1418,  2.5148,\n",
    "          2.5203,  6.3401,  2.0071,  1.8402,  4.9471,  1.5682,  1.7145,  3.8844,\n",
    "          1.2596,  1.2787,  2.7972,  0.6402,  0.0000,  1.6522],\n",
    "        [64.6351,  3.0961,  8.2211,  6.8130,  4.8287,  3.3772,  2.1273,  2.5043,\n",
    "          2.5074,  6.3145,  1.9946,  1.8289,  4.9230,  1.5577,  1.7038,  3.8632,\n",
    "          1.2487,  1.2712,  2.7784,  0.6357,  0.0000,  1.6409],\n",
    "        [64.3260,  3.0779,  8.1841,  6.7784,  4.8016,  3.3560,  2.1126,  2.4936,\n",
    "          2.4943,  6.2885,  1.9819,  1.8175,  4.8985,  1.5470,  1.6928,  3.8416,\n",
    "          1.2376,  1.2636,  2.7593,  0.6311,  0.0000,  1.6295],\n",
    "        [64.5792,  3.0928,  8.2144,  6.8068,  4.8238,  3.3734,  2.1247,  2.5024,\n",
    "          2.5051,  6.3098,  1.9923,  1.8268,  4.9186,  1.5558,  1.7018,  3.8593,\n",
    "          1.2466,  1.2698,  2.7749,  0.6349,  0.0000,  1.6389],\n",
    "        [63.5627,  3.0328,  8.0927,  6.6930,  4.7348,  3.3035,  2.0763,  2.4672,\n",
    "          2.4619,  6.2242,  1.9506,  1.7892,  4.8379,  1.5205,  1.6658,  3.7884,\n",
    "          1.2101,  1.2449,  2.7120,  0.6197,  0.0000,  1.6012],\n",
    "        [64.5792,  3.0928,  8.2144,  6.8068,  4.8238,  3.3734,  2.1247,  2.5024,\n",
    "          2.5051,  6.3098,  1.9923,  1.8268,  4.9186,  1.5558,  1.7018,  3.8593,\n",
    "          1.2466,  1.2698,  2.7749,  0.6349,  0.0000,  1.6389],\n",
    "        [64.3263,  3.0779,  8.1841,  6.7785,  4.8016,  3.3560,  2.1126,  2.4936,\n",
    "          2.4943,  6.2885,  1.9819,  1.8175,  4.8985,  1.5470,  1.6928,  3.8416,\n",
    "          1.2376,  1.2636,  2.7593,  0.6311,  0.0000,  1.6295],\n",
    "        [64.2321,  3.0723,  8.1728,  6.7679,  4.7934,  3.3495,  2.1081,  2.4904,\n",
    "          2.4903,  6.2806,  1.9780,  1.8140,  4.8910,  1.5437,  1.6895,  3.8351,\n",
    "          1.2342,  1.2613,  2.7534,  0.6297,  0.0000,  1.6260],\n",
    "        [64.2907,  3.0758,  8.1799,  6.7745,  4.7985,  3.3535,  2.1109,  2.4924,\n",
    "          2.4928,  6.2855,  1.9804,  1.8161,  4.8957,  1.5458,  1.6916,  3.8392,\n",
    "          1.2363,  1.2627,  2.7571,  0.6306,  0.0000,  1.6282],\n",
    "        [65.1269,  3.1252,  8.2800,  6.8680,  4.8717,  3.4110,  2.1507,  2.5213,\n",
    "          2.5283,  6.3559,  2.0148,  1.8471,  4.9620,  1.5747,  1.7212,  3.8975,\n",
    "          1.2664,  1.2833,  2.8089,  0.6430,  0.0000,  1.6591],\n",
    "        [64.2912,  3.0758,  8.1799,  6.7745,  4.7986,  3.3536,  2.1110,  2.4924,\n",
    "          2.4928,  6.2856,  1.9804,  1.8161,  4.8957,  1.5458,  1.6916,  3.8392,\n",
    "          1.2363,  1.2628,  2.7571,  0.6306,  0.0000,  1.6282],\n",
    "        [64.5770,  3.0927,  8.2142,  6.8065,  4.8236,  3.3732,  2.1246,  2.5023,\n",
    "          2.5050,  6.3096,  1.9922,  1.8268,  4.9184,  1.5557,  1.7017,  3.8591,\n",
    "          1.2466,  1.2698,  2.7748,  0.6348,  0.0000,  1.6388],\n",
    "        [64.4834,  3.0872,  8.2029,  6.7960,  4.8154,  3.3668,  2.1201,  2.4991,\n",
    "          2.5010,  6.3017,  1.9883,  1.8233,  4.9110,  1.5524,  1.6984,  3.8526,\n",
    "          1.2432,  1.2675,  2.7690,  0.6334,  0.0000,  1.6353],\n",
    "        [64.6300,  3.0958,  8.2205,  6.8125,  4.8282,  3.3769,  2.1271,  2.5041,\n",
    "          2.5072,  6.3141,  1.9944,  1.8287,  4.9226,  1.5575,  1.7036,  3.8628,\n",
    "          1.2485,  1.2711,  2.7781,  0.6356,  0.0000,  1.6407],\n",
    "        [64.4953,  3.0879,  8.2044,  6.7974,  4.8164,  3.3676,  2.1207,  2.4995,\n",
    "          2.5015,  6.3027,  1.9888,  1.8237,  4.9119,  1.5529,  1.6988,  3.8534,\n",
    "          1.2436,  1.2678,  2.7698,  0.6336,  0.0000,  1.6357]], dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_data = decoder_data[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_pred  = S_model.evaluate(decoder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77182955, 0.7760769 , 0.7759796 , 0.77182955, 0.7759796 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Decoder import Decoder\n",
    "from SurrogateModel import SurrogateModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 22\n",
    "h_nodes = 512\n",
    "scale = 2\n",
    "num_layers = 5\n",
    "embed_dim = 8\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder model loaded from:  /Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/decoder_model.pth\n"
     ]
    }
   ],
   "source": [
    "decoder_model = Decoder(x_dim, embed_dim= embed_dim, h_nodes = h_nodes, dropout = dropout, scale = scale, num_layers= num_layers, load_path = '/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/decoder_model.pth').to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with random vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vector = torch.rand(5, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output = decoder_model(random_vector)\n",
    "decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_model = SurrogateModel('/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/surrogate_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = S_model.evaluate(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75241435, 0.7893968 , 0.7689091 , 0.76963234, 0.7433951 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
