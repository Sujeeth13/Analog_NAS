{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.SurrogateModel import SurrogateModel\n",
    "from env.Decoder import Decoder\n",
    "from env.VQVAE_environment import VQVAE_Env, RenderCallback\n",
    "from env.RLTrainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_model = '/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/surrogate_model.json'\n",
    "codebook = '/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/codebook.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_config = {\n",
    "    \"out_dim\": 22,           # Output dimension\n",
    "    \"embed_dim\": 8,          # Embedding dimension\n",
    "    \"h_nodes\": 512,          # Number of hidden nodes\n",
    "    \"dropout\": 0.2,          # Dropout rate\n",
    "    \"scale\": 2,              # Scale factor\n",
    "    \"num_layers\": 5,         # Number of layers\n",
    "    \"load_path\": '/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/decoder_model.pth', # Path to load model weights\n",
    "}\n",
    "\n",
    "env_config = {\n",
    "    \"embed_dim\": decoder_config['embed_dim'],    # Embedding dimension\n",
    "    \"num_embeddings\": 14,           # Number of embeddings\n",
    "    \"max_allowed_actions\": 200,      # Maximum allowed actions\n",
    "    \"consider_previous_actions\": False, # Consider previous actions\n",
    "    \"num_previous_actions\": 2,       # Number of previous actions to consider  \n",
    "    \"render_mode\": 'human',          # Render mode\n",
    "    \"render_data\": '/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/render/architectures_trained_on.npy',  # Data for rendering\n",
    "    \"render_labels\": '/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/render/labels.npy',   # Labels for rendering\n",
    "    \"render_log_dir\": 'trainingLogs',                  # Directory for logging data\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    \"model\": \"A2C\",                # Model type ('PPO', 'A2C', 'DQN', etc.)\n",
    "    \"policy\": 'MlpPolicy',  # Policy type\n",
    "    \"total_timesteps\": 1000000,       # Total number of timesteps\n",
    "    \"verbose\": 0,                  # Verbosity level\n",
    "    \"tensorboard_log\": env_config['render_log_dir'],  # Tensorboard log directory\n",
    "    \"n_steps\": 128,               # Number of steps to run for each environment per update\n",
    "    \"progress_bar\": False,          # Whether to display a progress bar\n",
    "    \"n_epochs\": 15,                # Number of epochs\n",
    "    \"batch_size\": 32,              # Batch size\n",
    "}\n",
    "\n",
    "log_config = {\n",
    "    \"project\": 'PPO Training',                          # Project name in wandb\n",
    "    #\"entity\": 'trex-ai',                            # Entity name in wandb\n",
    "    \"sync_tensorboard\": True,                           # Whether to sync TensorBoard\n",
    "    \"save_code\": True,                                  # Whether to save code in wandb\n",
    "    \"model_save_path\": env_config['render_log_dir'],    # Path to save the model\n",
    "    \"gradient_save_freq\": 100,                          # Frequency to save gradients\n",
    "    \"verbose\": 2,                                       # Verbosity level\n",
    "}\n",
    "\n",
    "# Example of initializing the Trainer class with these configurations\n",
    "# trainer = Trainer(\n",
    "#     surrogate_path=\"path_to_surrogate_model.pt\",\n",
    "#     codebook_path=\"path_to_codebook.pt\",\n",
    "#     decoder_config=decoder_config,\n",
    "#     env_config=env_config,\n",
    "#     model_config=model_config,\n",
    "#     log_config=log_config\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surrogate model loaded from:  /Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/surrogate_model.json\n",
      "Codebook loaded from:  /Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/codebook.pth\n",
      "Decoder model loaded from:  /Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/decoder_model.pth\n",
      "Environment check passed\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(surrogate_path=surrogate_model, \n",
    "                  codebook_path=codebook, \n",
    "                  decoder_config=decoder_config, \n",
    "                  env_config=env_config, \n",
    "                  model_config=model_config, \n",
    "                  log_config=log_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masaficontact\u001b[0m (\u001b[33mtrex-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/wandb/run-20240501_011633-7j4qyayo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/trex-ai/PPO%20Training/runs/7j4qyayo' target=\"_blank\">giddy-frog-17</a></strong> to <a href='https://wandb.ai/trex-ai/PPO%20Training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/trex-ai/PPO%20Training' target=\"_blank\">https://wandb.ai/trex-ai/PPO%20Training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/trex-ai/PPO%20Training/runs/7j4qyayo' target=\"_blank\">https://wandb.ai/trex-ai/PPO%20Training/runs/7j4qyayo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6e9a0e7a014f98b52a738afc8ee713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='9.306 MB of 9.306 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>rollout/ep_len_mean</td><td>▆▅▆▅▆▆▇▃▆▆▅█▆▆▆█▄▇▅▅▆▅▆▃▅▅▅▇▃▅▄▅▆▄▆▅▅▁▆▃</td></tr><tr><td>rollout/ep_rew_mean</td><td>▄▂▅▆▆▆▆█▃▆█▆▄▆▅▄▄▃▄▆▁▄▄█▅▅▃▆▆▇▆▃▆▆▄▇▇▁▆▇</td></tr><tr><td>time/fps</td><td>▁▁▁▁▂▂▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>train/entropy_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▂▁▂▂▅▁▂▂▃▃▂▂▁▂▄▂▃▂▂▂▂▃█</td></tr><tr><td>train/explained_variance</td><td>█▇█▁▇██▇█▇▇▇██████▅██▇▇████▇█▇███████▇█▇</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/policy_loss</td><td>▅▄▅▄▁▄▅▂▄▄▄▄▃▅▆▄▅▆▅▄▅▃▅▅▄▅█▇▆▅▆▁▄▄▄▄▅▄▅▅</td></tr><tr><td>train/value_loss</td><td>▂▁▃▁█▃▃▄▄▃▃▄▂▃▂▂▆▃▁▃▂▆▁▄▃█▄▂▆▁▂▅▂▃▂▂▂▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>998400</td></tr><tr><td>rollout/ep_len_mean</td><td>81.88</td></tr><tr><td>rollout/ep_rew_mean</td><td>0.78208</td></tr><tr><td>time/fps</td><td>329.0</td></tr><tr><td>train/entropy_loss</td><td>-4.56044</td></tr><tr><td>train/explained_variance</td><td>-0.07321</td></tr><tr><td>train/learning_rate</td><td>0.0007</td></tr><tr><td>train/policy_loss</td><td>0.00543</td></tr><tr><td>train/value_loss</td><td>0.00571</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">giddy-frog-17</strong> at: <a href='https://wandb.ai/trex-ai/PPO%20Training/runs/7j4qyayo' target=\"_blank\">https://wandb.ai/trex-ai/PPO%20Training/runs/7j4qyayo</a><br/> View project at: <a href='https://wandb.ai/trex-ai/PPO%20Training' target=\"_blank\">https://wandb.ai/trex-ai/PPO%20Training</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240501_011633-7j4qyayo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/models/a2c_MlpPolicy_2_1000000\"\n",
    "trainer.save_model(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surrogate model loaded from:  /Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/surrogate_model.json\n",
      "Codebook loaded from:  /Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/codebook.pth\n",
      "Decoder model loaded from:  /Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/decoder_model.pth\n",
      "Environment check passed\n"
     ]
    }
   ],
   "source": [
    "decoder_config = {\n",
    "    \"out_dim\": 22,           # Output dimension\n",
    "    \"embed_dim\": 8,          # Embedding dimension\n",
    "    \"h_nodes\": 512,          # Number of hidden nodes\n",
    "    \"dropout\": 0.2,          # Dropout rate\n",
    "    \"scale\": 2,              # Scale factor\n",
    "    \"num_layers\": 5,         # Number of layers\n",
    "    \"load_path\": '/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/models/decoder_model.pth', # Path to load model weights\n",
    "}\n",
    "\n",
    "env_config = {\n",
    "    \"embed_dim\": decoder_config['embed_dim'],    # Embedding dimension\n",
    "    \"num_embeddings\": 14,           # Number of embeddings\n",
    "    \"max_allowed_actions\": 200,      # Maximum allowed actions\n",
    "    \"consider_previous_actions\": True, # Consider previous actions\n",
    "    \"num_previous_actions\": 2,       # Number of previous actions to consider  \n",
    "    \"render_mode\": 'human',          # Render mode\n",
    "    \"render_data\": '/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/render/architectures_trained_on.npy',  # Data for rendering\n",
    "    \"render_labels\": '/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/env/render/labels.npy',   # Labels for rendering\n",
    "    \"render_log_dir\": 'trainingLogs',                  # Directory for logging data\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    \"model\": \"A2C\",                # Model type ('PPO', 'A2C', 'DQN', etc.)\n",
    "    \"policy\": 'MultiInputPolicy',  # Policy type\n",
    "    \"total_timesteps\": 1000000,       # Total number of timesteps\n",
    "    \"verbose\": 0,                  # Verbosity level\n",
    "    \"tensorboard_log\": env_config['render_log_dir'],  # Tensorboard log directory\n",
    "    \"n_steps\": 2048,               # Number of steps to run for each environment per update\n",
    "    \"progress_bar\": False,          # Whether to display a progress bar\n",
    "    \"n_epochs\": 10,                # Number of epochs\n",
    "    \"batch_size\": 64,              # Batch size\n",
    "}\n",
    "\n",
    "log_config = {\n",
    "    \"project\": 'PPO Training',                          # Project name in wandb\n",
    "    #\"entity\": 'trex-ai',                            # Entity name in wandb\n",
    "    \"sync_tensorboard\": True,                           # Whether to sync TensorBoard\n",
    "    \"save_code\": True,                                  # Whether to save code in wandb\n",
    "    \"model_save_path\": env_config['render_log_dir'],    # Path to save the model\n",
    "    \"gradient_save_freq\": 100,                          # Frequency to save gradients\n",
    "    \"verbose\": 2,                                       # Verbosity level\n",
    "}\n",
    "\n",
    "trainer = Trainer(surrogate_path=surrogate_model, \n",
    "                  codebook_path=codebook, \n",
    "                  decoder_config=decoder_config, \n",
    "                  env_config=env_config, \n",
    "                  model_config=model_config, \n",
    "                  log_config=log_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masaficontact\u001b[0m (\u001b[33mtrex-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/wandb/run-20240501_105343-4z8crrs4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/trex-ai/PPO%20Training/runs/4z8crrs4' target=\"_blank\">autumn-leaf-20</a></strong> to <a href='https://wandb.ai/trex-ai/PPO%20Training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/trex-ai/PPO%20Training' target=\"_blank\">https://wandb.ai/trex-ai/PPO%20Training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/trex-ai/PPO%20Training/runs/4z8crrs4' target=\"_blank\">https://wandb.ai/trex-ai/PPO%20Training/runs/4z8crrs4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba2bb7b9f404622a324a456bb3a6ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='9.280 MB of 9.280 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▃▆█</td></tr><tr><td>rollout/ep_len_mean</td><td>█▁▁▁</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▆█▇</td></tr><tr><td>time/fps</td><td>▁▂▆█</td></tr><tr><td>train/entropy_loss</td><td>▁▄▇█</td></tr><tr><td>train/explained_variance</td><td>▁▇██</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁</td></tr><tr><td>train/policy_loss</td><td>▁▆██</td></tr><tr><td>train/value_loss</td><td>▇█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>819200</td></tr><tr><td>rollout/ep_len_mean</td><td>2.06</td></tr><tr><td>rollout/ep_rew_mean</td><td>0.8107</td></tr><tr><td>time/fps</td><td>326.0</td></tr><tr><td>train/entropy_loss</td><td>-2.07218</td></tr><tr><td>train/explained_variance</td><td>0.98376</td></tr><tr><td>train/learning_rate</td><td>0.0007</td></tr><tr><td>train/policy_loss</td><td>-0.00069</td></tr><tr><td>train/value_loss</td><td>0.00279</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">autumn-leaf-20</strong> at: <a href='https://wandb.ai/trex-ai/PPO%20Training/runs/4z8crrs4' target=\"_blank\">https://wandb.ai/trex-ai/PPO%20Training/runs/4z8crrs4</a><br/> View project at: <a href='https://wandb.ai/trex-ai/PPO%20Training' target=\"_blank\">https://wandb.ai/trex-ai/PPO%20Training</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240501_105343-4z8crrs4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/models/a2c_MultiInputPolicy_2_1000000\"\n",
    "trainer.save_model(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_steps(env, model, num_steps):\n",
    "    obs = env.reset()\n",
    "    for _ in range(num_steps):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    return obs\n",
    "\n",
    "def evaluate_model(trainer, num_episodes, num_steps):\n",
    "\n",
    "    model = trainer.model\n",
    "    env = trainer.env\n",
    "    surrogate_model = trainer.surrogate_model\n",
    "    decoder_model = trainer.decoder_model\n",
    "\n",
    "    accuracy = []\n",
    "    for i in range(num_episodes):\n",
    "        rl_output = run_steps(env, model, num_steps)\n",
    "        rl_output_tensor = torch.tensor(rl_output, dtype=torch.float32)  # Add batch dimension\n",
    "        decoder_output = decoder_model(rl_output_tensor)\n",
    "        calculated_accuracy = surrogate_model.evaluate(decoder_output)\n",
    "        print(f\"Accuracy: {calculated_accuracy} for episode {i}\")\n",
    "        accuracy.append(calculated_accuracy)\n",
    "    \n",
    "    print(f\"Average accuracy: {sum(accuracy)/num_episodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_model('/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/trainingLogs/models/rklmkht6/model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.798057496547699 for episode 0\n",
      "Accuracy: 0.7889947295188904 for episode 1\n",
      "Accuracy: 0.9471520185470581 for episode 2\n",
      "Accuracy: 0.7839134335517883 for episode 3\n",
      "Accuracy: 0.9190993905067444 for episode 4\n",
      "Accuracy: 0.7772524356842041 for episode 5\n",
      "Accuracy: 0.7889947295188904 for episode 6\n",
      "Accuracy: 0.7889947295188904 for episode 7\n",
      "Accuracy: 0.9243929982185364 for episode 8\n",
      "Accuracy: 0.7725493907928467 for episode 9\n",
      "Accuracy: 0.9243929982185364 for episode 10\n",
      "Accuracy: 0.7349642515182495 for episode 11\n",
      "Accuracy: 0.7551933526992798 for episode 12\n",
      "Accuracy: 0.819848895072937 for episode 13\n",
      "Accuracy: 0.9325972199440002 for episode 14\n",
      "Accuracy: 0.7681959271430969 for episode 15\n",
      "Accuracy: 0.759606122970581 for episode 16\n",
      "Accuracy: 0.9228904843330383 for episode 17\n",
      "Accuracy: 0.736478328704834 for episode 18\n",
      "Accuracy: 0.7753796577453613 for episode 19\n",
      "Accuracy: 0.9325860738754272 for episode 20\n",
      "Accuracy: 0.7889947295188904 for episode 21\n",
      "Accuracy: 0.7725493907928467 for episode 22\n",
      "Accuracy: 0.7348170280456543 for episode 23\n",
      "Accuracy: 0.8088371157646179 for episode 24\n",
      "Accuracy: 0.7513466477394104 for episode 25\n",
      "Accuracy: 0.9285473227500916 for episode 26\n",
      "Accuracy: 0.7704378962516785 for episode 27\n",
      "Accuracy: 0.798057496547699 for episode 28\n",
      "Accuracy: 0.9243929982185364 for episode 29\n",
      "Accuracy: 0.9324069023132324 for episode 30\n",
      "Accuracy: 0.9202268123626709 for episode 31\n",
      "Accuracy: 0.7839134335517883 for episode 32\n",
      "Accuracy: 0.7889947295188904 for episode 33\n",
      "Accuracy: 0.9272683262825012 for episode 34\n",
      "Accuracy: 0.8088371157646179 for episode 35\n",
      "Accuracy: 0.7349642515182495 for episode 36\n",
      "Accuracy: 0.7889947295188904 for episode 37\n",
      "Accuracy: 0.7889947295188904 for episode 38\n",
      "Accuracy: 0.757368803024292 for episode 39\n",
      "Accuracy: 0.7889947295188904 for episode 40\n",
      "Accuracy: 0.9156166315078735 for episode 41\n",
      "Accuracy: 0.9281994104385376 for episode 42\n",
      "Accuracy: 0.7753796577453613 for episode 43\n",
      "Accuracy: 0.7606016993522644 for episode 44\n",
      "Accuracy: 0.7889947295188904 for episode 45\n",
      "Accuracy: 0.7889947295188904 for episode 46\n",
      "Accuracy: 0.7725493907928467 for episode 47\n",
      "Accuracy: 0.7372422218322754 for episode 48\n",
      "Accuracy: 0.7535715699195862 for episode 49\n",
      "Accuracy: 0.9429131746292114 for episode 50\n",
      "Accuracy: 0.7692904472351074 for episode 51\n",
      "Accuracy: 0.7686992287635803 for episode 52\n",
      "Accuracy: 0.7889947295188904 for episode 53\n",
      "Accuracy: 0.9319303035736084 for episode 54\n",
      "Accuracy: 0.7404413819313049 for episode 55\n",
      "Accuracy: 0.7889947295188904 for episode 56\n",
      "Accuracy: 0.9441887140274048 for episode 57\n",
      "Accuracy: 0.944547712802887 for episode 58\n",
      "Accuracy: 0.770458459854126 for episode 59\n",
      "Accuracy: 0.7644068598747253 for episode 60\n",
      "Accuracy: 0.759606122970581 for episode 61\n",
      "Accuracy: 0.9342565536499023 for episode 62\n",
      "Accuracy: 0.7889947295188904 for episode 63\n",
      "Accuracy: 0.7686992287635803 for episode 64\n",
      "Accuracy: 0.9227997064590454 for episode 65\n",
      "Accuracy: 0.9319303035736084 for episode 66\n",
      "Accuracy: 0.7733031511306763 for episode 67\n",
      "Accuracy: 0.8088371157646179 for episode 68\n",
      "Accuracy: 0.7551933526992798 for episode 69\n",
      "Accuracy: 0.9285473227500916 for episode 70\n",
      "Accuracy: 0.7889947295188904 for episode 71\n",
      "Accuracy: 0.7644068598747253 for episode 72\n",
      "Accuracy: 0.9233819842338562 for episode 73\n",
      "Accuracy: 0.9227997064590454 for episode 74\n",
      "Accuracy: 0.7889947295188904 for episode 75\n",
      "Accuracy: 0.7644068598747253 for episode 76\n",
      "Accuracy: 0.7889947295188904 for episode 77\n",
      "Accuracy: 0.7889947295188904 for episode 78\n",
      "Accuracy: 0.7889947295188904 for episode 79\n",
      "Accuracy: 0.7889947295188904 for episode 80\n",
      "Accuracy: 0.9438520669937134 for episode 81\n",
      "Accuracy: 0.7692904472351074 for episode 82\n",
      "Accuracy: 0.9342565536499023 for episode 83\n",
      "Accuracy: 0.7839134335517883 for episode 84\n",
      "Accuracy: 0.9285473227500916 for episode 85\n",
      "Accuracy: 0.9369305968284607 for episode 86\n",
      "Accuracy: 0.9235689640045166 for episode 87\n",
      "Accuracy: 0.9238914251327515 for episode 88\n",
      "Accuracy: 0.9141677618026733 for episode 89\n",
      "Accuracy: 0.7348170280456543 for episode 90\n",
      "Accuracy: 0.7889947295188904 for episode 91\n",
      "Accuracy: 0.7889947295188904 for episode 92\n",
      "Accuracy: 0.7753796577453613 for episode 93\n",
      "Accuracy: 0.7733031511306763 for episode 94\n",
      "Accuracy: 0.7376570105552673 for episode 95\n",
      "Accuracy: 0.7889947295188904 for episode 96\n",
      "Accuracy: 0.7839134335517883 for episode 97\n",
      "Accuracy: 0.7575494050979614 for episode 98\n",
      "Accuracy: 0.7562592625617981 for episode 99\n",
      "Average Accuracy: 0.822519063949585\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate_accuracy(num_episodes=100, num_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_model('/Users/tawab/Desktop/columbia/Courses/Spring2024/HPML/Project/Analog_NAS/trainingLogs/models/uenl6yuv/model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9238914251327515 for episode 0\n",
      "Accuracy: 0.7889947295188904 for episode 1\n",
      "Accuracy: 0.7889947295188904 for episode 2\n",
      "Accuracy: 0.7818193435668945 for episode 3\n",
      "Accuracy: 0.7889947295188904 for episode 4\n",
      "Accuracy: 0.9326378107070923 for episode 5\n",
      "Accuracy: 0.7889947295188904 for episode 6\n",
      "Accuracy: 0.9325860738754272 for episode 7\n",
      "Accuracy: 0.7889947295188904 for episode 8\n",
      "Accuracy: 0.9238914251327515 for episode 9\n",
      "Accuracy: 0.759606122970581 for episode 10\n",
      "Accuracy: 0.819848895072937 for episode 11\n",
      "Accuracy: 0.7575494050979614 for episode 12\n",
      "Accuracy: 0.9322266578674316 for episode 13\n",
      "Accuracy: 0.9290140271186829 for episode 14\n",
      "Accuracy: 0.7889947295188904 for episode 15\n",
      "Accuracy: 0.7818193435668945 for episode 16\n",
      "Accuracy: 0.7348170280456543 for episode 17\n",
      "Accuracy: 0.7734160423278809 for episode 18\n",
      "Accuracy: 0.7889947295188904 for episode 19\n",
      "Accuracy: 0.7704378962516785 for episode 20\n",
      "Accuracy: 0.7744229435920715 for episode 21\n",
      "Accuracy: 0.7889947295188904 for episode 22\n",
      "Accuracy: 0.925092875957489 for episode 23\n",
      "Accuracy: 0.9238914251327515 for episode 24\n",
      "Accuracy: 0.7889947295188904 for episode 25\n",
      "Accuracy: 0.770458459854126 for episode 26\n",
      "Accuracy: 0.9285473227500916 for episode 27\n",
      "Accuracy: 0.9189534187316895 for episode 28\n",
      "Accuracy: 0.7889947295188904 for episode 29\n",
      "Accuracy: 0.757368803024292 for episode 30\n",
      "Accuracy: 0.9324069023132324 for episode 31\n",
      "Accuracy: 0.7535715699195862 for episode 32\n",
      "Accuracy: 0.9141677618026733 for episode 33\n",
      "Accuracy: 0.7889947295188904 for episode 34\n",
      "Accuracy: 0.7889947295188904 for episode 35\n",
      "Accuracy: 0.7551933526992798 for episode 36\n",
      "Accuracy: 0.7839134335517883 for episode 37\n",
      "Accuracy: 0.9373398423194885 for episode 38\n",
      "Accuracy: 0.7599714398384094 for episode 39\n",
      "Accuracy: 0.759606122970581 for episode 40\n",
      "Accuracy: 0.7839134335517883 for episode 41\n",
      "Accuracy: 0.7535715699195862 for episode 42\n",
      "Accuracy: 0.798057496547699 for episode 43\n",
      "Accuracy: 0.9238914251327515 for episode 44\n",
      "Accuracy: 0.9342565536499023 for episode 45\n",
      "Accuracy: 0.7889947295188904 for episode 46\n",
      "Accuracy: 0.9190993905067444 for episode 47\n",
      "Accuracy: 0.9290140271186829 for episode 48\n",
      "Accuracy: 0.7686756253242493 for episode 49\n",
      "Accuracy: 0.7889947295188904 for episode 50\n",
      "Accuracy: 0.7692904472351074 for episode 51\n",
      "Accuracy: 0.925092875957489 for episode 52\n",
      "Accuracy: 0.770458459854126 for episode 53\n",
      "Accuracy: 0.7733031511306763 for episode 54\n",
      "Accuracy: 0.944547712802887 for episode 55\n",
      "Accuracy: 0.7466604113578796 for episode 56\n",
      "Accuracy: 0.7889947295188904 for episode 57\n",
      "Accuracy: 0.7889947295188904 for episode 58\n",
      "Accuracy: 0.759606122970581 for episode 59\n",
      "Accuracy: 0.944547712802887 for episode 60\n",
      "Accuracy: 0.9141677618026733 for episode 61\n",
      "Accuracy: 0.7889947295188904 for episode 62\n",
      "Accuracy: 0.7704378962516785 for episode 63\n",
      "Accuracy: 0.7889947295188904 for episode 64\n",
      "Accuracy: 0.9238914251327515 for episode 65\n",
      "Accuracy: 0.7889947295188904 for episode 66\n",
      "Accuracy: 0.7889947295188904 for episode 67\n",
      "Accuracy: 0.9353243112564087 for episode 68\n",
      "Accuracy: 0.7575494050979614 for episode 69\n",
      "Accuracy: 0.7599714398384094 for episode 70\n",
      "Accuracy: 0.9318768382072449 for episode 71\n",
      "Accuracy: 0.7889947295188904 for episode 72\n",
      "Accuracy: 0.7889947295188904 for episode 73\n",
      "Accuracy: 0.7686756253242493 for episode 74\n",
      "Accuracy: 0.9326378107070923 for episode 75\n",
      "Accuracy: 0.7753796577453613 for episode 76\n",
      "Accuracy: 0.7889947295188904 for episode 77\n",
      "Accuracy: 0.9281994104385376 for episode 78\n",
      "Accuracy: 0.7733031511306763 for episode 79\n",
      "Accuracy: 0.7889947295188904 for episode 80\n",
      "Accuracy: 0.759606122970581 for episode 81\n",
      "Accuracy: 0.9202268123626709 for episode 82\n",
      "Accuracy: 0.9322266578674316 for episode 83\n",
      "Accuracy: 0.9369305968284607 for episode 84\n",
      "Accuracy: 0.7889947295188904 for episode 85\n",
      "Accuracy: 0.9155168533325195 for episode 86\n",
      "Accuracy: 0.7889947295188904 for episode 87\n",
      "Accuracy: 0.7466604113578796 for episode 88\n",
      "Accuracy: 0.9238914251327515 for episode 89\n",
      "Accuracy: 0.7348170280456543 for episode 90\n",
      "Accuracy: 0.7692904472351074 for episode 91\n",
      "Accuracy: 0.9238914251327515 for episode 92\n",
      "Accuracy: 0.7686756253242493 for episode 93\n",
      "Accuracy: 0.7889947295188904 for episode 94\n",
      "Accuracy: 0.9441887140274048 for episode 95\n",
      "Accuracy: 0.7771551012992859 for episode 96\n",
      "Accuracy: 0.7889947295188904 for episode 97\n",
      "Accuracy: 0.7733031511306763 for episode 98\n",
      "Accuracy: 0.759606122970581 for episode 99\n",
      "Average Accuracy: 0.8264170289039612\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate_accuracy(num_episodes=100, num_steps=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
